{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Due Date: December 11th"
      ],
      "metadata": {
        "id": "F3ZF3oYIJ3KW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzptQhdh0pUr"
      },
      "source": [
        "# Vaccine Development with Dynamic Programming\n",
        "\n",
        "You are the CEO of a biotech company which is considering the development of a new vaccine. Starting at phase 0 (state 0), the drug develpment can stay in the same state or advance to \"phase 1  with promising results\" (state 1) or advance to \"phase 1 with disappointing results\" (state 2), or fail completely (state 4). At phase 1, the drug can stay in the same state, fail or become a success (state 3), in which case you will sell its patent to a big pharma company for \\$10 million.\n",
        "These state transitions happen from month to month, and at each state, you have the option to make an additional investment of \\$100,000, which increases the chances of success.\n",
        "\n",
        "After careful study, your analysts develop the program below to simulate different scenarios using statistical data from similar projects.\n",
        "\n",
        "Use a discount factor of 0.996.\n",
        "\n",
        "-  Write a policy iteration or value iteration code to compute the value of this project. Please print the full V (value function) vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnAvrShs6ecs"
      },
      "source": [
        "import numpy as np\n",
        "class MDP():\n",
        "  def __init__(self):\n",
        "    self.A = [0, 1]\n",
        "    self.S = [0, 1, 2, 3, 4]\n",
        "\n",
        "    P0 = np.array([[0.5, .15, .15, 0, .20],\n",
        "                   [0, .5, .0, .25, .25],\n",
        "                   [0, 0, .15, .05, .8],\n",
        "                   [0, 0, 0, 0, 1],\n",
        "                   [0, 0, 0, 0, 1]])\n",
        "\n",
        "    R0 = np.array([0, 0, 0, 10, 0])\n",
        "\n",
        "    P1 = np.array([[0.5, .25, .15, 0, .10],\n",
        "                   [0, .5, .0, .35, .15],\n",
        "                   [0, 0, .20, .05, .75],\n",
        "                   [0, 0, 0, 0, 1],\n",
        "                   [0, 0, 0, 0, 1]])\n",
        "\n",
        "    R1 = np.array([-0.1, -0.1, -0.1, 10, 0])\n",
        "\n",
        "    self.P = [P0, P1]\n",
        "    self.R = [R0, R1]\n",
        "\n",
        "  def step(self, s, a):\n",
        "    s_prime = np.random.choice(len(self.S), p=self.P[a][s])\n",
        "    R = self.R[a][s]\n",
        "    if s_prime == 4:\n",
        "      done = True\n",
        "    else:\n",
        "      done = False\n",
        "    return s_prime, R, done\n",
        "\n",
        "  def simulate(self, s, a, π):\n",
        "    done = False\n",
        "    t = 0\n",
        "    history = []\n",
        "    while not done:\n",
        "      if t > 0:\n",
        "        a = π[s]\n",
        "      s_prime, R, done = self.step(s, a)\n",
        "      history.append((s, a, R))\n",
        "      s = s_prime\n",
        "      t += 1\n",
        "\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the transition probability matrices and the reward vector as follows:"
      ],
      "metadata": {
        "id": "xgAiJxSnZtkH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-rfjh_37kmX"
      },
      "source": [
        "mdp = MDP()\n",
        "P = mdp.P\n",
        "R = mdp.R\n",
        "\n",
        "\n",
        "s = 2 # current state\n",
        "s_prime = 4  # next state\n",
        "a = 1  # chosen action\n",
        "\n",
        "# Probability of transition from state s (2) to s_prime (4) if action == a (1):\n",
        "print(P[a][s, s_prime])\n",
        "\n",
        "# Reward at state s if action = a\n",
        "print(R[a][s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWfK-47V8I08"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}